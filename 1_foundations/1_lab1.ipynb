{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouter API Key exists and begins sk-or-v1\n",
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the keys\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting guide\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder!\n",
    "# If you get a NameError - head over to the guides folder to learn about NameErrors\n",
    "\n",
    "openai = OpenAI()\n",
    "openrouter = OpenAI(base_url=\"https://api.openrouter.ai/v1\", api_key=openrouter_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n",
      "An error occurred with OpenRouter: Connection error.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAn error occurred with OpenRouter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m     response_openrouter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse_openrouter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "\n",
    "from typing import cast\n",
    "from openai.types.chat import ChatCompletionMessageParam\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=cast(list[ChatCompletionMessageParam], messages)\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "try:\n",
    "    # Now let's try the OpenRouter API\n",
    "    # This uses DeepSeek R1, a free model available on OpenRouter\n",
    "    # If you get an error here, check your OpenRouter API key and the troubleshooting guide\n",
    "    response_openrouter = openrouter.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1-0528:free\",\n",
    "        messages=cast(list[ChatCompletionMessageParam], messages)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred with OpenRouter: {e}\")\n",
    "    response_openrouter = None\n",
    "\n",
    "\n",
    "print(response_openrouter.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "One promising business area for an Agentic AI solution is **Supply Chain and Logistics Management**.\n",
       "\n",
       "### Why Supply Chain and Logistics?\n",
       "- **Complex, dynamic environment:** Supply chains involve numerous stakeholders, fluctuating demand, unpredictable disruptions (e.g., weather, geopolitical events), and complex coordination among suppliers, manufacturers, distributors, and retailers.\n",
       "- **High impact from optimization:** Even small improvements in routing, inventory management, or demand forecasting can lead to substantial cost savings and service improvements.\n",
       "- **Scalability and adaptability:** An autonomous AI agent can continuously monitor and adapt to changes in real-time, coordinating tasks across geographies, modes of transport, and inventory levels without constant human intervention.\n",
       "\n",
       "### What would an Agentic AI do here?\n",
       "- Autonomously optimize delivery routes and schedules dynamically based on live traffic, weather, and capacity data.\n",
       "- Proactively manage inventory levels by predicting demand spikes or shortages and coordinating replenishments across multiple warehouses.\n",
       "- Negotiate procurement contracts or shipping arrangements with suppliers and carriers using natural language interfaces and automated decision-making.\n",
       "- Detect and mitigate risks by autonomously responding to disruptions, rerouting shipments, or adjusting production plans.\n",
       "- Integrate with ERP and IoT systems to gather data and orchestrate operations end-to-end.\n",
       "\n",
       "### Potential benefits:\n",
       "- Increased efficiency and reduced costs through continuous, autonomous optimization.\n",
       "- Faster response to disruptions and improved supply chain resilience.\n",
       "- Reduced human workload in coordination and decision-making, allowing teams to focus on strategic tasks.\n",
       "- Enhanced customer satisfaction due to improved delivery reliability and transparency.\n",
       "\n",
       "This area is complex enough to benefit significantly from agentic autonomy but also has clear, high-value practical applications making it ripe for innovative AI solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "question = \"Please propose a business area that might be ripe for an Agentic AI solution.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(  \n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "display(Markdown(business_idea))\n",
    "# And repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A key pain point for deploying Agentic AI in **Supply Chain and Logistics Management** is:\n",
       "\n",
       "### Pain Point: **Fragmented and Siloed Data Across Stakeholders Hindering Real-Time Coordination and Decision-Making**\n",
       "\n",
       "---\n",
       "\n",
       "### Explanation:\n",
       "Supply chains often involve multiple independent organizations (suppliers, manufacturers, carriers, warehouses, retailers) using disparate legacy systems, proprietary formats, and disconnected databases. This fragmentation leads to:\n",
       "\n",
       "- **Poor data visibility and quality:** Critical information such as inventory levels, shipment status, demand signals, or disruption alerts may be delayed, incomplete, or inconsistent.\n",
       "- **Slow and manual reconciliation:** Human operators spend significant time gathering, validating, and reconciling information before making decisions.\n",
       "- **Reduced agility and suboptimal decisions:** Without a unified, real-time view, the AI agent’s ability to autonomously optimize operations is hampered. It may fail to react timely or make less informed trade-offs.\n",
       "- **Integration complexity:** Integrating with numerous ERP, warehouse management systems (WMS), transportation management systems (TMS), and IoT sensors demands significant engineering effort and ongoing maintenance.\n",
       "\n",
       "---\n",
       "\n",
       "### Why Addressing This Pain Point Matters for Agentic AI:\n",
       "\n",
       "- Agentic AI depends heavily on clean, centralized, and real-time data feeds to perceive the complex environment accurately and act autonomously.\n",
       "- Overcoming data silos enables end-to-end orchestration and dynamic decision-making at scale.\n",
       "- Ensuring interoperability and data sharing agreements among stakeholders may be necessary, raising trust and governance challenges that the AI system needs to accommodate.\n",
       "\n",
       "---\n",
       "\n",
       "### Potential Solution Approaches:\n",
       "\n",
       "- Develop standardized data schemas and APIs or leverage supply chain blockchain ledgers to improve data sharing trustworthiness.\n",
       "- Employ real-time data ingestion pipelines and data fusion techniques to consolidate fragmented inputs.\n",
       "- Design the agent with uncertainty-aware reasoning to handle incomplete or noisy data robustly.\n",
       "- Implement privacy-preserving federated learning or multi-party computation if data sharing is sensitive.\n",
       "\n",
       "---\n",
       "\n",
       "### Summary:\n",
       "**Fragmented, siloed, and inconsistent data across the supply chain ecosystem is a critical pain point limiting the effective deployment of Agentic AI solutions for autonomous supply chain management. Addressing it unlocks the AI’s potential to optimize, adapt, and orchestrate complex logistics dynamically and efficiently.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = f\"Please propose a pain point for {business_idea}.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "pain_point = response.choices[0].message.content    \n",
    "display(Markdown(pain_point))\n",
    "\n",
    "#question = f\"Propose a solution for {pain_point}.\"\n",
    "#messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here is a detailed proposal for an **Agentic AI solution** tackling the pain point of **Fragmented and Siloed Data Across Stakeholders Hindering Real-Time Coordination and Decision-Making** in Supply Chain and Logistics Management:\n",
       "\n",
       "---\n",
       "\n",
       "## Agentic AI Solution Proposal: **Unified Collaborative Data Fabric with Agentic Orchestration Layer**\n",
       "\n",
       "### 1. **Concept Overview**\n",
       "\n",
       "Build a **multi-stakeholder collaborative data fabric** combining standardized data exchange, privacy-preserving federation, and real-time data fusion, overlaid by an **Agentic AI orchestration layer** that continuously perceives, reasons, and acts upon the unified supply chain state.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **Key Components**\n",
       "\n",
       "#### a) **Standardized Interoperable Data Layer**\n",
       "\n",
       "- **Adopt Open Supply Chain Standards:** Implement data schemas based on GS1, EPCIS, or create an industry consortium standardized ontology (e.g., product IDs, event types, timestamps).\n",
       "- **API Gateway Mesh:** Provide a modular API gateway layer for each stakeholder system (ERP, WMS, TMS, IoT platforms), performing protocol translation and schema mapping to the unified data model.\n",
       "- **Blockchain or Distributed Ledger:** Use permissioned blockchain to record key supply chain events, ensuring immutability and enhancing trust, enabling transparent provenance and dispute resolution without exposing proprietary data.\n",
       "\n",
       "#### b) **Privacy-Preserving Federated Data Aggregation**\n",
       "\n",
       "- **Federated Data Integration:** Instead of centralized data pooling, employ federated learning and multiparty computation methods to aggregate insights and global supply chain state information while keeping sensitive data on-premise.\n",
       "- **Access Control & Governance:** Implement fine-grained attribute-based encryption and consent management allowing stakeholders to control what data is shared, how it is used, and audit the usage.\n",
       "\n",
       "#### c) **Real-Time Data Ingestion and Fusion Engine**\n",
       "\n",
       "- **Streaming Pipelines:** Connect all stakeholder APIs, IoT sensors, and external data feeds into a robust event streaming platform (Apache Kafka, Pulsar).\n",
       "- **Data Cleaning & Fusion:** Automatically resolve conflicts, fill gaps, deduplicate, and timestamp-align data streams to construct a coherent, real-time state vector of inventory, shipments, and demand signals.\n",
       "\n",
       "#### d) **Agentic AI Orchestration Layer**\n",
       "\n",
       "- **Multi-Modal Perception:** Utilize advanced perception models combining structured data, sensor feeds, and external intelligence (weather, traffic) to maintain situation awareness.\n",
       "- **Uncertainty-Aware Reasoning:** Apply probabilistic graphical models or Bayesian networks to reason under incomplete/noisy data conditions and quantify confidence in state estimations.\n",
       "- **Dynamic Decision-Making:** Employ reinforcement learning or model-predictive control agents that autonomously recommend and execute actions (routing changes, order adjustments, contingencies) based on real-time supply chain state.\n",
       "- **Collaborative Planning:** Agents negotiate and coordinate across stakeholders via smart contracts or interaction protocols embedded in the data fabric, balancing competing priorities transparently.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **Benefits**\n",
       "\n",
       "- **End-to-End Visibility:** Eliminates data black boxes by harmonizing data flows, enabling a single “source of truth” for the agent.\n",
       "- **Faster Decision Cycles:** Minimizes manual reconciliation delays, accelerating reaction to disruptions or demand shifts.\n",
       "- **Strengthened Trust & Compliance:** Blockchain and encryption-based governance frameworks reduce data-sharing hesitancy.\n",
       "- **Scalable Integration:** API gateways and federated approaches reduce integration engineering overhead and improve adaptability to evolving systems.\n",
       "- **Robustness to Imperfect Data:** Uncertainty modeling allows safe autonomous actions despite data gaps.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. **Implementation Roadmap**\n",
       "\n",
       "| Phase               | Actions                                                                                      |\n",
       "|---------------------|----------------------------------------------------------------------------------------------|\n",
       "| **Pilot & Standardization** | Collaborate with key supply chain partners to define common data schemas and governance policies. Deploy API gateways to onboard legacy systems.                       |\n",
       "| **Federated Data Layer Deployment** | Integrate federated learning frameworks and blockchain ledger nodes to enable secure data sharing and event recording among stakeholders.                            |\n",
       "| **Agentic AI Development** | Develop and train perception, reasoning, and decision-making agent modules with uncertainty handling on fused real-time data. Conduct simulations.                      |\n",
       "| **End-to-End Testing & Iteration** | Run controlled pilot scenarios; refine data cleaning, fusion, agent policies, and stakeholder feedback loops. Expand network of participants gradually.             |\n",
       "| **Scale & Optimize**    | Optimize system performance, enhance AI policies with continuous learning, and implement automated compliance reporting for governance.                             |\n",
       "\n",
       "---\n",
       "\n",
       "### 5. **Risks & Mitigations**\n",
       "\n",
       "| Risk                                    | Mitigation                                                      |\n",
       "|-----------------------------------------|----------------------------------------------------------------|\n",
       "| Data privacy concerns and reluctance    | Robust encryption, consent management, and federated approaches |\n",
       "| Legacy system incompatibilities          | Modular API gateways with customizable adapters                |\n",
       "| Consensus on standards slow to form       | Use industry bodies and regulators to accelerate agreements    |\n",
       "| Added system complexity and cost         | Phased rollout with ROI demonstration and modular adoption      |\n",
       "\n",
       "---\n",
       "\n",
       "### **Summary**\n",
       "\n",
       "By architecting a **collaborative, privacy-conscious data fabric** combined with a sophisticated **agentic AI orchestration layer**, the solution addresses the core impediment of fragmented, siloed data. It unlocks real-time, trustworthy supply chain visibility and autonomous decision-making capabilities that significantly improve coordination, agility, and resilience in modern supply chains.\n",
       "\n",
       "---\n",
       "\n",
       "If you'd like, I can help design specific architecture diagrams, technology stack recommendations, or agent decision frameworks for this approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = f\"Propose an Agentic AI solution for {pain_point}.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")   \n",
    "\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
